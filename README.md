# ğŸ“ MCQ-Gen: AI-Powered Quiz Generator

Transform any text content into engaging, interactive multiple-choice quizzes using cutting-edge local AI technology. Built with Julia and powered by Ollama for complete privacy and offline functionality.

![MCQ-Gen Interface](gui/mcq-gen.png)

## âœ¨ What Makes MCQ-Gen Special?

**ğŸ¤– Intelligent Content Analysis**: Advanced AI understands context, key concepts, and learning objectives to generate pedagogically sound questions

**ğŸ¯ Adaptive Learning**: Choose difficulty levels (Easy/Medium/Hard) to match your knowledge level and learning goals

**ğŸ’¬ Interactive Experience**: Chat-like interface presents questions one-by-one with instant feedback and detailed explanations

**ğŸ”’ Complete Privacy**: Runs entirely on your machine with local models - no data ever leaves your computer

**âš¡ Lightning Fast**: Built with Julia for optimal performance and rapid quiz generation

## ğŸš€ Quick Start

### Prerequisites
- [Julia 1.6+](https://julialang.org/downloads/)
- [Ollama](https://ollama.ai/) installed and running

### One-Time Setup
```bash
# Clone and setup
git clone <repository-url>
cd mcq-gen
./init.sh    # Linux/Mac
# or
init.bat     # Windows
```

### Choose Your Interface

#### ğŸŒ Web GUI (Recommended)
```bash
./bin/mcq-server
```
Open [http://localhost:8000](http://localhost:8000) in your browser for the full interactive experience.

#### âŒ¨ï¸ Terminal CLI
```bash
./bin/mcq-cli
```

## ğŸ“– How It Works

### 1. **Input Your Content**
- Paste lecture notes, textbooks, articles, or any educational material
- Or simply type a topic you want to learn about
- The AI analyzes the content for key concepts and relationships

### 2. **Configure Your Quiz**
- Select difficulty level:
  - **Easy**: Basic recall and recognition
  - **Medium**: Understanding and application
  - **Hard**: Analysis and synthesis
- Set the number of questions (coming soon)

### 3. **Interactive Learning**
- Questions appear one at a time in a conversational format
- Get instant feedback on your answers
- Receive detailed explanations for correct answers
- Track your progress and understanding

## ğŸ› ï¸ Technical Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web GUI       â”‚    â”‚   Terminal CLI  â”‚    â”‚   Julia Core    â”‚
â”‚   (Vue.js)      â”‚â—„â”€â”€â–ºâ”‚   (TUI)         â”‚â—„â”€â”€â–ºâ”‚   (MCQGen.jl)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚   Ollama API    â”‚
                                               â”‚   (Local LLM)   â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components
- **MCQGen.jl**: Main orchestration module
- **Web.jl**: HTTP server and API endpoints
- **CLI.jl**: Terminal-based user interface
- **Ollama.jl**: Local LLM integration and prompt engineering

## ğŸ“š Documentation

- ğŸ“¥ **[Installation Guide](docs/INSTALLATION.md)** - Detailed setup for all platforms
- ğŸ‘¤ **[User Guide](docs/USER_GUIDE.md)** - Comprehensive usage instructions
- ğŸ—ï¸ **[Development Guide](docs/DEVELOPMENT.md)** - Architecture and contribution guidelines
- ğŸ”Œ **[API Reference](docs/API.md)** - Backend endpoints and module documentation

## ğŸ¯ Use Cases

### For Students
- Transform textbooks into practice quizzes
- Prepare for exams with targeted practice
- Test comprehension of complex topics
- Create study guides from lecture notes

### For Educators
- Generate assessment questions from curriculum materials
- Create differentiated quizzes for various skill levels
- Develop interactive classroom activities
- Provide immediate feedback to students

### For Content Creators
- Transform blog posts into engaging quizzes
- Create educational content for audiences
- Develop training materials with built-in assessment
- Generate discussion questions from content

## âš™ï¸ Configuration

### Ollama Setup
The application automatically creates and configures the optimal model on first run:
```bash
# View available models
ollama list

# Update model (if needed)
ollama pull <model-name>
```

### Environment Variables
```bash
# Optional: Custom Ollama endpoint
export OLLAMA_HOST=localhost:11434

# Optional: Custom port for web server
export MCQ_GEN_PORT=8000
```

## ğŸ”§ Troubleshooting

### Common Issues

**Ollama not detected**
```bash
# Start Ollama service
ollama serve

# Or check if running
ps aux | grep ollama
```

**Julia packages missing**
```bash
# From project directory
julia --project -e 'using Pkg; Pkg.instantiate()'
```

**Port already in use**
```bash
# Kill process on port 8000
lsof -ti:8000 | xargs kill -9
# Or use a different port
./bin/mcq-server 8080
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Development Guide](docs/DEVELOPMENT.md) for:
- Code style guidelines
- Architecture decisions
- Testing procedures
- Pull request process

### Development Setup
```bash
# Install development dependencies
julia --project -e 'using Pkg; Pkg.dev(".")'

# Run tests
julia test/runtests.jl
```

## ğŸ“Š Performance & Benchmarks

- **Quiz Generation**: ~2-5 seconds per question (varies by content complexity)
- **Memory Usage**: ~500MB base + model size
- **Supported Content**: Up to 50,000 characters per session
- **Concurrent Users**: Single-user optimized (web GUI supports multiple sessions)

## ğŸ†š Comparison

| Feature | MCQ-Gen | Online Tools | Traditional Methods |
|---------|---------|--------------|-------------------|
| **Privacy** | âœ… 100% Local | âŒ Cloud-based | âœ… Manual |
| **AI Quality** | âœ… Local LLM | âœ… Cloud AI | âŒ Human-created |
| **Cost** | âœ… Free | âŒ Subscription | âœ… Time-intensive |
| **Customization** | âœ… Full Control | âš ï¸ Limited | âœ… Unlimited |
| **Speed** | âœ… Fast | âœ… Fast | âŒ Slow |

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- **Ollama Team** - For making local AI accessible
- **Julia Community** - For the powerful programming language
- **Vue.js Team** - For the reactive frontend framework
- **Contributors** - For improving this project

---

**Built with â¤ï¸ for educators, students, and lifelong learners**

*Transform your learning experience today - no API keys required, no data shared, just pure AI-powered education.*
